{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-09T09:11:24.298370Z",
     "iopub.status.busy": "2025-11-09T09:11:24.297517Z",
     "iopub.status.idle": "2025-11-09T09:11:26.833315Z",
     "shell.execute_reply": "2025-11-09T09:11:26.832430Z",
     "shell.execute_reply.started": "2025-11-09T09:11:24.298336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/working/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:11:26.836008Z",
     "iopub.status.busy": "2025-11-09T09:11:26.835382Z",
     "iopub.status.idle": "2025-11-09T09:12:51.469207Z",
     "shell.execute_reply": "2025-11-09T09:12:51.468145Z",
     "shell.execute_reply.started": "2025-11-09T09:11:26.835973Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Shannu3766/bi_influence.git\n",
      "  Cloning https://github.com/Shannu3766/bi_influence.git to /tmp/pip-req-build-myovo80i\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/Shannu3766/bi_influence.git /tmp/pip-req-build-myovo80i\n",
      "  Resolved https://github.com/Shannu3766/bi_influence.git to commit a1f735bcf7f738164d6a532874f7fa3bc62f216c\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers>=4.30 in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (4.53.3)\n",
      "Requirement already satisfied: peft>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (0.16.0)\n",
      "Requirement already satisfied: datasets>=2.0 in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (4.4.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (4.67.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (1.2.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (1.9.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (2.2.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (3.20.0)\n",
      "Collecting pyarrow>=21.0.0 (from datasets>=2.0->adaptive_lora==2.1.0)\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (0.4.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (6.0.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->adaptive_lora==2.1.0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->adaptive_lora==2.1.0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->adaptive_lora==2.1.0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->adaptive_lora==2.1.0) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->adaptive_lora==2.1.0) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->adaptive_lora==2.1.0) (2.4.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft>=0.3.0->adaptive_lora==2.1.0) (7.1.3)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft>=0.3.0->adaptive_lora==2.1.0) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13->adaptive_lora==2.1.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13->adaptive_lora==2.1.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13->adaptive_lora==2.1.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13->adaptive_lora==2.1.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13->adaptive_lora==2.1.0)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13->adaptive_lora==2.1.0)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13->adaptive_lora==2.1.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13->adaptive_lora==2.1.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13->adaptive_lora==2.1.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13->adaptive_lora==2.1.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->adaptive_lora==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30->adaptive_lora==2.1.0) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30->adaptive_lora==2.1.0) (0.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->adaptive_lora==2.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->adaptive_lora==2.1.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->adaptive_lora==2.1.0) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->adaptive_lora==2.1.0) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->adaptive_lora==2.1.0) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->adaptive_lora==2.1.0) (3.6.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0->adaptive_lora==2.1.0) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0->adaptive_lora==2.1.0) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0->adaptive_lora==2.1.0) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0->adaptive_lora==2.1.0) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0->adaptive_lora==2.1.0) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.0->adaptive_lora==2.1.0) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->adaptive_lora==2.1.0) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.0->adaptive_lora==2.1.0) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.0->adaptive_lora==2.1.0) (2.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->adaptive_lora==2.1.0) (3.0.3)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->adaptive_lora==2.1.0) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->adaptive_lora==2.1.0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->adaptive_lora==2.1.0) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->adaptive_lora==2.1.0) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->adaptive_lora==2.1.0) (2024.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (1.22.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->adaptive_lora==2.1.0) (2024.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0->adaptive_lora==2.1.0) (1.3.1)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m272.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m253.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m266.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m233.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m280.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m243.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m254.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m231.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m251.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m258.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m255.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: adaptive_lora\n",
      "  Building wheel for adaptive_lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for adaptive_lora: filename=adaptive_lora-2.1.0-py3-none-any.whl size=9240 sha256=3795bf6f9a3faae6de2d8523d476ff5f436fcf1a628b55c5d108b982fb41b071\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-n5p77z1p/wheels/4b/91/1d/e153ff3aa3759d6ccdcc4706d8559f1cbfaa4aa22b992958cd\n",
      "Successfully built adaptive_lora\n",
      "Installing collected packages: pyarrow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, adaptive_lora\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 19.0.1\n",
      "    Uninstalling pyarrow-19.0.1:\n",
      "      Successfully uninstalled pyarrow-19.0.1\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed adaptive_lora-2.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyarrow-22.0.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install git+https://github.com/Shannu3766/bi_influence.git\n",
    "\n",
    "!pip install --upgrade --no-cache-dir git+https://github.com/Shannu3766/bi_influence.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:12:51.470876Z",
     "iopub.status.busy": "2025-11-09T09:12:51.470479Z",
     "iopub.status.idle": "2025-11-09T09:12:55.794841Z",
     "shell.execute_reply": "2025-11-09T09:12:55.793767Z",
     "shell.execute_reply.started": "2025-11-09T09:12:51.470822Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-11-09T09:12:55.797454Z",
     "iopub.status.busy": "2025-11-09T09:12:55.797158Z",
     "iopub.status.idle": "2025-11-09T09:13:14.470937Z",
     "shell.execute_reply": "2025-11-09T09:13:14.470121Z",
     "shell.execute_reply.started": "2025-11-09T09:12:55.797413Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets==2.20.0\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pyarrow==15.0.2\n",
      "  Downloading pyarrow-15.0.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting transformers==4.44.2\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting evaluate==0.4.2\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (1.26.4)\n",
      "Collecting pyarrow-hotfix (from datasets==2.20.0)\n",
      "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.20.0)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (0.70.18)\n",
      "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets==2.20.0)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (3.13.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2025.11.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.5.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.2->datasets==2.20.0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.2->datasets==2.20.0) (1.2.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2025.10.5)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.20.0)\n",
      "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.20.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.20.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.20.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.20.0) (1.17.0)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets==2.20.0) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets==2.20.0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets==2.20.0) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets==2.20.0) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets==2.20.0) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets==2.20.0) (2024.2.0)\n",
      "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-15.0.2-cp311-cp311-manylinux_2_28_x86_64.whl (38.3 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m253.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m247.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m271.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m298.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m298.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m286.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m307.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
      "Installing collected packages: pyarrow-hotfix, fsspec, dill, multiprocess, tokenizers, pyarrow, datasets, transformers, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.10.0\n",
      "    Uninstalling fsspec-2025.10.0:\n",
      "      Successfully uninstalled fsspec-2025.10.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.4.0\n",
      "    Uninstalling dill-0.4.0:\n",
      "      Successfully uninstalled dill-0.4.0\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.18\n",
      "    Uninstalling multiprocess-0.70.18:\n",
      "      Successfully uninstalled multiprocess-0.70.18\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.2\n",
      "    Uninstalling tokenizers-0.21.2:\n",
      "      Successfully uninstalled tokenizers-0.21.2\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 22.0.0\n",
      "    Uninstalling pyarrow-22.0.0:\n",
      "      Successfully uninstalled pyarrow-22.0.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.4.1\n",
      "    Uninstalling datasets-4.4.1:\n",
      "      Successfully uninstalled datasets-4.4.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.53.3\n",
      "    Uninstalling transformers-4.53.3:\n",
      "      Successfully uninstalled transformers-4.53.3\n",
      "  Attempting uninstall: evaluate\n",
      "    Found existing installation: evaluate 0.4.6\n",
      "    Uninstalling evaluate-0.4.6:\n",
      "      Successfully uninstalled evaluate-0.4.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "s3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2024.5.0 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 evaluate-0.4.2 fsspec-2024.5.0 multiprocess-0.70.16 pyarrow-15.0.2 pyarrow-hotfix-0.7 tokenizers-0.19.1 transformers-4.44.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets==2.20.0 pyarrow==15.0.2 transformers==4.44.2 evaluate==0.4.2 --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:13:14.472157Z",
     "iopub.status.busy": "2025-11-09T09:13:14.471906Z",
     "iopub.status.idle": "2025-11-09T09:13:14.476755Z",
     "shell.execute_reply": "2025-11-09T09:13:14.475919Z",
     "shell.execute_reply.started": "2025-11-09T09:13:14.472131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip uninstall adaptive_lora -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:13:14.478198Z",
     "iopub.status.busy": "2025-11-09T09:13:14.477769Z",
     "iopub.status.idle": "2025-11-09T09:13:14.496105Z",
     "shell.execute_reply": "2025-11-09T09:13:14.495486Z",
     "shell.execute_reply.started": "2025-11-09T09:13:14.478168Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/Shannu3766/bi_influence.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:13:14.498957Z",
     "iopub.status.busy": "2025-11-09T09:13:14.498733Z",
     "iopub.status.idle": "2025-11-09T09:13:18.430059Z",
     "shell.execute_reply": "2025-11-09T09:13:18.428862Z",
     "shell.execute_reply.started": "2025-11-09T09:13:14.498940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 泅 Step 1: Install Dependencies and Package\n",
    "# ============================================================\n",
    "!pip install -q datasets evaluate accelerate scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:13:18.431590Z",
     "iopub.status.busy": "2025-11-09T09:13:18.431279Z",
     "iopub.status.idle": "2025-11-09T09:13:22.327120Z",
     "shell.execute_reply": "2025-11-09T09:13:22.326244Z",
     "shell.execute_reply.started": "2025-11-09T09:13:18.431561Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets evaluate accelerate scikit-learn pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:13:22.328603Z",
     "iopub.status.busy": "2025-11-09T09:13:22.328274Z",
     "iopub.status.idle": "2025-11-09T09:13:56.019670Z",
     "shell.execute_reply": "2025-11-09T09:13:56.018935Z",
     "shell.execute_reply.started": "2025-11-09T09:13:22.328570Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Tensor size changed, may indicate binary incompatibility. Expected 64 from C header, got 80 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.ChunkedArray size changed, may indicate binary incompatibility. Expected 64 from C header, got 72 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib._Tabular size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Table size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Tensor size changed, may indicate binary incompatibility. Expected 64 from C header, got 80 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.ChunkedArray size changed, may indicate binary incompatibility. Expected 64 from C header, got 72 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib._Tabular size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Table size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "2025-11-09 09:13:33.470079: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762679613.859807      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762679613.974212      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 笨 Adaptive LoRA + DeepSeek 1.3B on WikiText\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from torch.utils.data import DataLoader\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from adaptive_lora.callbacks import AdaptiveLoRACallback\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:13:56.021153Z",
     "iopub.status.busy": "2025-11-09T09:13:56.020515Z",
     "iopub.status.idle": "2025-11-09T09:14:07.667888Z",
     "shell.execute_reply": "2025-11-09T09:14:07.667193Z",
     "shell.execute_reply.started": "2025-11-09T09:13:56.021130Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1313884c2324101b1bbc44841933ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/793 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde4889bc83948e287f5dc6929b122ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f38675e1b594a839f069184093b997c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06760087fc54ef8a3e9251d0c94fb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de2c91c1ca042df93036d6eff265b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.69G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29115e60628a4caca0202f7df368682e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1ｸ鞘Ε Load Model and Tokenizer\n",
    "# ============================================================\n",
    "model_name = \"deepseek-ai/deepseek-coder-1.3b-base\"  # 笨 smaller model (fits Kaggle GPUs)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",       # 笨 uses both GPUs automatically\n",
    "    low_cpu_mem_usage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:14:07.668880Z",
     "iopub.status.busy": "2025-11-09T09:14:07.668639Z",
     "iopub.status.idle": "2025-11-09T09:14:12.773500Z",
     "shell.execute_reply": "2025-11-09T09:14:12.772594Z",
     "shell.execute_reply.started": "2025-11-09T09:14:07.668847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,145,728 || all params: 1,349,617,664 || trainable%: 0.2331\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2ｸ鞘Ε Apply LoRA\n",
    "# ============================================================\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:14:12.774587Z",
     "iopub.status.busy": "2025-11-09T09:14:12.774362Z",
     "iopub.status.idle": "2025-11-09T09:14:16.581697Z",
     "shell.execute_reply": "2025-11-09T09:14:16.581031Z",
     "shell.execute_reply.started": "2025-11-09T09:14:12.774570Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c21b3fbc544a77ac34f561b592a511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d677907af34d21b3434bb522579869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/733k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9c3721c3604525a0423c5526089384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3e3addf1f045daa9c352b1e7d042a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/657k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38da6192ed0d4ae78693284908ba4ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff1c679c7634c328c882628ebda5588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6cb809ad9246c1b3339dee397bfb8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "\n",
    "train_texts = dataset[\"train\"][\"text\"][:8000]\n",
    "val_texts = dataset[\"validation\"][\"text\"][:1000]\n",
    "test_texts = dataset[\"test\"][\"text\"][:1000]\n",
    "\n",
    "def tokenize_data(texts):\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    enc[\"labels\"] = enc[\"input_ids\"].clone()\n",
    "    return Dataset.from_dict({k: v.tolist() for k, v in enc.items()})\n",
    "\n",
    "train_dataset = tokenize_data(train_texts)\n",
    "val_dataset = tokenize_data(val_texts)\n",
    "test_dataset = tokenize_data(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:14:16.582743Z",
     "iopub.status.busy": "2025-11-09T09:14:16.582504Z",
     "iopub.status.idle": "2025-11-09T09:14:23.659830Z",
     "shell.execute_reply": "2025-11-09T09:14:23.658986Z",
     "shell.execute_reply.started": "2025-11-09T09:14:16.582724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4ｸ鞘Ε Prepare Validation Loader (for BI computation)\n",
    "# ============================================================\n",
    "def collate_fn(batch):\n",
    "    keys = batch[0].keys()\n",
    "    collated = {k: torch.tensor([x[k] for x in batch]) for k in keys}\n",
    "    return collated\n",
    "\n",
    "val_loader_for_callback = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=2,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:14:23.660914Z",
     "iopub.status.busy": "2025-11-09T09:14:23.660673Z",
     "iopub.status.idle": "2025-11-09T09:14:23.678695Z",
     "shell.execute_reply": "2025-11-09T09:14:23.678022Z",
     "shell.execute_reply.started": "2025-11-09T09:14:23.660896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5ｸ鞘Ε Adaptive LoRA Callback\n",
    "# ============================================================\n",
    "adaptive_callback = AdaptiveLoRACallback(\n",
    "    total_rank=512,\n",
    "    tau=0.4,\n",
    "    val_dataloader=val_loader_for_callback,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:14:23.679973Z",
     "iopub.status.busy": "2025-11-09T09:14:23.679737Z",
     "iopub.status.idle": "2025-11-09T09:14:23.698520Z",
     "shell.execute_reply": "2025-11-09T09:14:23.697834Z",
     "shell.execute_reply.started": "2025-11-09T09:14:23.679945Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6ｸ鞘Ε Offline-safe compute_metrics\n",
    "# ============================================================\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Computes BLEU, Perplexity, and Loss 窶 works fully offline.\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    logits = torch.tensor(logits)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    # Compute loss & perplexity\n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    shift_labels = labels[..., 1:].contiguous()\n",
    "    loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    perplexity = torch.exp(loss)\n",
    "\n",
    "    # Decode text\n",
    "    preds = torch.argmax(logits, dim=-1)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Compute BLEU\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    bleu_scores = [\n",
    "        sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothie)\n",
    "        for pred, ref in zip(decoded_preds, decoded_labels)\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"loss\": loss.item(),\n",
    "        \"perplexity\": perplexity.item(),\n",
    "        \"bleu\": float(np.mean(bleu_scores))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:14:23.699692Z",
     "iopub.status.busy": "2025-11-09T09:14:23.699398Z",
     "iopub.status.idle": "2025-11-09T09:15:02.433073Z",
     "shell.execute_reply": "2025-11-09T09:15:02.432376Z",
     "shell.execute_reply.started": "2025-11-09T09:14:23.699671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 洟 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "泅 Starting Adaptive LoRA fine-tuning on WikiText...\n",
      "\n",
      "--- AdaptiveLoRA: Preparing ranks for Epoch 1 ---\n",
      "Computing BI importance scores (pre-training)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocating new ranks based on BI scores...\n",
      "Applying new ranks to LoRA modules for this epoch...\n",
      "  - base_model.model.model.layers.0.self_attn.q_proj: r=8 竊 7 (Score: 0.8227)\n",
      "  - base_model.model.model.layers.0.self_attn.k_proj: r=8 竊 4 (Score: 0.5497)\n",
      "  - base_model.model.model.layers.0.self_attn.v_proj: r=8 竊 7 (Score: 0.8052)\n",
      "  - base_model.model.model.layers.0.self_attn.o_proj: r=8 竊 4 (Score: 0.5330)\n",
      "  - base_model.model.model.layers.1.self_attn.q_proj: r=8 竊 5 (Score: 0.6496)\n",
      "  - base_model.model.model.layers.1.self_attn.k_proj: r=8 竊 9 (Score: 0.9009)\n",
      "  - base_model.model.model.layers.1.self_attn.v_proj: r=8 竊 3 (Score: 0.4647)\n",
      "  - base_model.model.model.layers.1.self_attn.o_proj: r=8 竊 7 (Score: 0.7840)\n",
      "  - base_model.model.model.layers.2.self_attn.q_proj: r=8 竊 3 (Score: 0.4980)\n",
      "  - base_model.model.model.layers.2.self_attn.k_proj: r=8 竊 7 (Score: 0.7778)\n",
      "  - base_model.model.model.layers.2.self_attn.v_proj: r=8 竊 5 (Score: 0.6710)\n",
      "  - base_model.model.model.layers.2.self_attn.o_proj: r=8 竊 3 (Score: 0.4708)\n",
      "  - base_model.model.model.layers.3.self_attn.q_proj: r=8 竊 5 (Score: 0.6855)\n",
      "  - base_model.model.model.layers.3.self_attn.k_proj: r=8 竊 5 (Score: 0.6800)\n",
      "  - base_model.model.model.layers.3.self_attn.v_proj: r=8 竊 3 (Score: 0.4817)\n",
      "  - base_model.model.model.layers.3.self_attn.o_proj: r=8 竊 4 (Score: 0.5409)\n",
      "  - base_model.model.model.layers.4.self_attn.q_proj: r=8 竊 6 (Score: 0.7324)\n",
      "  - base_model.model.model.layers.4.self_attn.k_proj: r=8 竊 6 (Score: 0.7197)\n",
      "  - base_model.model.model.layers.4.self_attn.v_proj: r=8 竊 5 (Score: 0.6773)\n",
      "  - base_model.model.model.layers.4.self_attn.o_proj: r=8 竊 3 (Score: 0.5286)\n",
      "  - base_model.model.model.layers.5.self_attn.q_proj: r=8 竊 6 (Score: 0.7233)\n",
      "  - base_model.model.model.layers.5.self_attn.k_proj: r=8 竊 4 (Score: 0.6045)\n",
      "  - base_model.model.model.layers.5.self_attn.v_proj: r=8 竊 7 (Score: 0.8018)\n",
      "  - base_model.model.model.layers.5.self_attn.o_proj: r=8 竊 6 (Score: 0.7456)\n",
      "  - base_model.model.model.layers.6.self_attn.q_proj: r=8 竊 11 (Score: 1.0000)\n",
      "  - base_model.model.model.layers.6.self_attn.k_proj: r=8 (Unchanged, Score: 0.8376)\n",
      "  - base_model.model.model.layers.6.self_attn.v_proj: r=8 竊 3 (Score: 0.4938)\n",
      "  - base_model.model.model.layers.6.self_attn.o_proj: r=8 竊 4 (Score: 0.5382)\n",
      "  - base_model.model.model.layers.7.self_attn.q_proj: r=8 竊 3 (Score: 0.4767)\n",
      "  - base_model.model.model.layers.7.self_attn.k_proj: r=8 竊 3 (Score: 0.5001)\n",
      "  - base_model.model.model.layers.7.self_attn.v_proj: r=8 竊 3 (Score: 0.5041)\n",
      "  - base_model.model.model.layers.7.self_attn.o_proj: r=8 竊 5 (Score: 0.7095)\n",
      "  - base_model.model.model.layers.8.self_attn.q_proj: r=8 竊 4 (Score: 0.5848)\n",
      "  - base_model.model.model.layers.8.self_attn.k_proj: r=8 竊 6 (Score: 0.7274)\n",
      "  - base_model.model.model.layers.8.self_attn.v_proj: r=8 竊 3 (Score: 0.5149)\n",
      "  - base_model.model.model.layers.8.self_attn.o_proj: r=8 竊 6 (Score: 0.7335)\n",
      "  - base_model.model.model.layers.9.self_attn.q_proj: r=8 竊 3 (Score: 0.4914)\n",
      "  - base_model.model.model.layers.9.self_attn.k_proj: r=8 竊 5 (Score: 0.6515)\n",
      "  - base_model.model.model.layers.9.self_attn.v_proj: r=8 竊 2 (Score: 0.2267)\n",
      "  - base_model.model.model.layers.9.self_attn.o_proj: r=8 竊 5 (Score: 0.6361)\n",
      "  - base_model.model.model.layers.10.self_attn.q_proj: r=8 竊 9 (Score: 0.9277)\n",
      "  - base_model.model.model.layers.10.self_attn.k_proj: r=8 竊 7 (Score: 0.8205)\n",
      "  - base_model.model.model.layers.10.self_attn.v_proj: r=8 竊 9 (Score: 0.9049)\n",
      "  - base_model.model.model.layers.10.self_attn.o_proj: r=8 竊 2 (Score: 0.3112)\n",
      "  - base_model.model.model.layers.11.self_attn.q_proj: r=8 竊 4 (Score: 0.6289)\n",
      "  - base_model.model.model.layers.11.self_attn.k_proj: r=8 竊 5 (Score: 0.6594)\n",
      "  - base_model.model.model.layers.11.self_attn.v_proj: r=8 (Unchanged, Score: 0.8836)\n",
      "  - base_model.model.model.layers.11.self_attn.o_proj: r=8 竊 6 (Score: 0.7715)\n",
      "  - base_model.model.model.layers.12.self_attn.q_proj: r=8 竊 11 (Score: 0.9747)\n",
      "  - base_model.model.model.layers.12.self_attn.k_proj: r=8 竊 6 (Score: 0.7591)\n",
      "  - base_model.model.model.layers.12.self_attn.v_proj: r=8 (Unchanged, Score: 0.8594)\n",
      "  - base_model.model.model.layers.12.self_attn.o_proj: r=8 竊 4 (Score: 0.5452)\n",
      "  - base_model.model.model.layers.13.self_attn.q_proj: r=8 竊 5 (Score: 0.6862)\n",
      "  - base_model.model.model.layers.13.self_attn.k_proj: r=8 竊 5 (Score: 0.6661)\n",
      "  - base_model.model.model.layers.13.self_attn.v_proj: r=8 竊 5 (Score: 0.6998)\n",
      "  - base_model.model.model.layers.13.self_attn.o_proj: r=8 竊 11 (Score: 0.9823)\n",
      "  - base_model.model.model.layers.14.self_attn.q_proj: r=8 竊 6 (Score: 0.7366)\n",
      "  - base_model.model.model.layers.14.self_attn.k_proj: r=8 竊 6 (Score: 0.7535)\n",
      "  - base_model.model.model.layers.14.self_attn.v_proj: r=8 竊 2 (Score: 0.3820)\n",
      "  - base_model.model.model.layers.14.self_attn.o_proj: r=8 竊 6 (Score: 0.7102)\n",
      "  - base_model.model.model.layers.15.self_attn.q_proj: r=8 竊 11 (Score: 0.9785)\n",
      "  - base_model.model.model.layers.15.self_attn.k_proj: r=8 竊 7 (Score: 0.8111)\n",
      "  - base_model.model.model.layers.15.self_attn.v_proj: r=8 竊 2 (Score: 0.3170)\n",
      "  - base_model.model.model.layers.15.self_attn.o_proj: r=8 竊 3 (Score: 0.5081)\n",
      "  - base_model.model.model.layers.16.self_attn.q_proj: r=8 竊 9 (Score: 0.8919)\n",
      "  - base_model.model.model.layers.16.self_attn.k_proj: r=8 竊 5 (Score: 0.6551)\n",
      "  - base_model.model.model.layers.16.self_attn.v_proj: r=8 (Unchanged, Score: 0.8446)\n",
      "  - base_model.model.model.layers.16.self_attn.o_proj: r=8 竊 7 (Score: 0.8275)\n",
      "  - base_model.model.model.layers.17.self_attn.q_proj: r=8 竊 6 (Score: 0.7125)\n",
      "  - base_model.model.model.layers.17.self_attn.k_proj: r=8 竊 6 (Score: 0.7614)\n",
      "  - base_model.model.model.layers.17.self_attn.v_proj: r=8 竊 3 (Score: 0.4895)\n",
      "  - base_model.model.model.layers.17.self_attn.o_proj: r=8 竊 4 (Score: 0.5461)\n",
      "  - base_model.model.model.layers.18.self_attn.q_proj: r=8 竊 3 (Score: 0.4575)\n",
      "  - base_model.model.model.layers.18.self_attn.k_proj: r=8 竊 2 (Score: 0.3026)\n",
      "  - base_model.model.model.layers.18.self_attn.v_proj: r=8 (Unchanged, Score: 0.8677)\n",
      "  - base_model.model.model.layers.18.self_attn.o_proj: r=8 竊 2 (Score: 0.2308)\n",
      "  - base_model.model.model.layers.19.self_attn.q_proj: r=8 (Unchanged, Score: 0.8569)\n",
      "  - base_model.model.model.layers.19.self_attn.k_proj: r=8 竊 4 (Score: 0.5332)\n",
      "  - base_model.model.model.layers.19.self_attn.v_proj: r=8 竊 4 (Score: 0.5509)\n",
      "  - base_model.model.model.layers.19.self_attn.o_proj: r=8 竊 5 (Score: 0.6323)\n",
      "  - base_model.model.model.layers.20.self_attn.q_proj: r=8 竊 6 (Score: 0.7491)\n",
      "  - base_model.model.model.layers.20.self_attn.k_proj: r=8 竊 4 (Score: 0.5434)\n",
      "  - base_model.model.model.layers.20.self_attn.v_proj: r=8 竊 5 (Score: 0.6999)\n",
      "  - base_model.model.model.layers.20.self_attn.o_proj: r=8 竊 4 (Score: 0.5482)\n",
      "  - base_model.model.model.layers.21.self_attn.q_proj: r=8 竊 5 (Score: 0.6645)\n",
      "  - base_model.model.model.layers.21.self_attn.k_proj: r=8 竊 10 (Score: 0.9531)\n",
      "  - base_model.model.model.layers.21.self_attn.v_proj: r=8 竊 4 (Score: 0.6101)\n",
      "  - base_model.model.model.layers.21.self_attn.o_proj: r=8 竊 6 (Score: 0.7169)\n",
      "  - base_model.model.model.layers.22.self_attn.q_proj: r=8 竊 5 (Score: 0.6411)\n",
      "  - base_model.model.model.layers.22.self_attn.k_proj: r=8 竊 3 (Score: 0.5245)\n",
      "  - base_model.model.model.layers.22.self_attn.v_proj: r=8 竊 3 (Score: 0.5015)\n",
      "  - base_model.model.model.layers.22.self_attn.o_proj: r=8 竊 4 (Score: 0.5903)\n",
      "  - base_model.model.model.layers.23.self_attn.q_proj: r=8 竊 9 (Score: 0.9184)\n",
      "  - base_model.model.model.layers.23.self_attn.k_proj: r=8 竊 3 (Score: 0.5192)\n",
      "  - base_model.model.model.layers.23.self_attn.v_proj: r=8 竊 10 (Score: 0.9374)\n",
      "  - base_model.model.model.layers.23.self_attn.o_proj: r=8 竊 1 (Score: 0.0000)\n",
      "笨 AdaptiveLoRA: Rank setup for Epoch 1 complete.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:34, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Perplexity</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.979621</td>\n",
       "      <td>395.290680</td>\n",
       "      <td>0.049199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.925492</td>\n",
       "      <td>374.462738</td>\n",
       "      <td>0.048382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.897400</td>\n",
       "      <td>5.916800</td>\n",
       "      <td>371.222076</td>\n",
       "      <td>0.045578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒 Epoch 0: Rank allocations logged to ./logs/adaptive_lora_epoch_logs.csv\n",
      "\n",
      "\n",
      "--- AdaptiveLoRA: Preparing ranks for Epoch 1 ---\n",
      "Computing BI importance scores (pre-training)...\n",
      "Allocating new ranks based on BI scores...\n",
      "Applying new ranks to LoRA modules for this epoch...\n",
      "  - base_model.model.model.layers.0.self_attn.q_proj: r=7 (Unchanged, Score: 0.8227)\n",
      "  - base_model.model.model.layers.0.self_attn.k_proj: r=4 (Unchanged, Score: 0.5497)\n",
      "  - base_model.model.model.layers.0.self_attn.v_proj: r=7 (Unchanged, Score: 0.8052)\n",
      "  - base_model.model.model.layers.0.self_attn.o_proj: r=4 (Unchanged, Score: 0.5330)\n",
      "  - base_model.model.model.layers.1.self_attn.q_proj: r=5 (Unchanged, Score: 0.6496)\n",
      "  - base_model.model.model.layers.1.self_attn.k_proj: r=9 (Unchanged, Score: 0.9009)\n",
      "  - base_model.model.model.layers.1.self_attn.v_proj: r=3 (Unchanged, Score: 0.4647)\n",
      "  - base_model.model.model.layers.1.self_attn.o_proj: r=7 (Unchanged, Score: 0.7840)\n",
      "  - base_model.model.model.layers.2.self_attn.q_proj: r=3 (Unchanged, Score: 0.4980)\n",
      "  - base_model.model.model.layers.2.self_attn.k_proj: r=7 (Unchanged, Score: 0.7778)\n",
      "  - base_model.model.model.layers.2.self_attn.v_proj: r=5 (Unchanged, Score: 0.6711)\n",
      "  - base_model.model.model.layers.2.self_attn.o_proj: r=3 (Unchanged, Score: 0.4709)\n",
      "  - base_model.model.model.layers.3.self_attn.q_proj: r=5 (Unchanged, Score: 0.6855)\n",
      "  - base_model.model.model.layers.3.self_attn.k_proj: r=5 (Unchanged, Score: 0.6800)\n",
      "  - base_model.model.model.layers.3.self_attn.v_proj: r=3 (Unchanged, Score: 0.4817)\n",
      "  - base_model.model.model.layers.3.self_attn.o_proj: r=4 (Unchanged, Score: 0.5409)\n",
      "  - base_model.model.model.layers.4.self_attn.q_proj: r=6 (Unchanged, Score: 0.7324)\n",
      "  - base_model.model.model.layers.4.self_attn.k_proj: r=6 (Unchanged, Score: 0.7197)\n",
      "  - base_model.model.model.layers.4.self_attn.v_proj: r=5 (Unchanged, Score: 0.6774)\n",
      "  - base_model.model.model.layers.4.self_attn.o_proj: r=3 (Unchanged, Score: 0.5286)\n",
      "  - base_model.model.model.layers.5.self_attn.q_proj: r=6 (Unchanged, Score: 0.7234)\n",
      "  - base_model.model.model.layers.5.self_attn.k_proj: r=4 (Unchanged, Score: 0.6045)\n",
      "  - base_model.model.model.layers.5.self_attn.v_proj: r=7 (Unchanged, Score: 0.8019)\n",
      "  - base_model.model.model.layers.5.self_attn.o_proj: r=6 (Unchanged, Score: 0.7456)\n",
      "  - base_model.model.model.layers.6.self_attn.q_proj: r=11 (Unchanged, Score: 1.0000)\n",
      "  - base_model.model.model.layers.6.self_attn.k_proj: r=8 (Unchanged, Score: 0.8376)\n",
      "  - base_model.model.model.layers.6.self_attn.v_proj: r=3 (Unchanged, Score: 0.4938)\n",
      "  - base_model.model.model.layers.6.self_attn.o_proj: r=4 (Unchanged, Score: 0.5382)\n",
      "  - base_model.model.model.layers.7.self_attn.q_proj: r=3 (Unchanged, Score: 0.4767)\n",
      "  - base_model.model.model.layers.7.self_attn.k_proj: r=3 (Unchanged, Score: 0.5002)\n",
      "  - base_model.model.model.layers.7.self_attn.v_proj: r=3 (Unchanged, Score: 0.5042)\n",
      "  - base_model.model.model.layers.7.self_attn.o_proj: r=5 (Unchanged, Score: 0.7095)\n",
      "  - base_model.model.model.layers.8.self_attn.q_proj: r=4 (Unchanged, Score: 0.5849)\n",
      "  - base_model.model.model.layers.8.self_attn.k_proj: r=6 (Unchanged, Score: 0.7274)\n",
      "  - base_model.model.model.layers.8.self_attn.v_proj: r=3 (Unchanged, Score: 0.5150)\n",
      "  - base_model.model.model.layers.8.self_attn.o_proj: r=6 (Unchanged, Score: 0.7337)\n",
      "  - base_model.model.model.layers.9.self_attn.q_proj: r=3 (Unchanged, Score: 0.4913)\n",
      "  - base_model.model.model.layers.9.self_attn.k_proj: r=5 (Unchanged, Score: 0.6516)\n",
      "  - base_model.model.model.layers.9.self_attn.v_proj: r=2 (Unchanged, Score: 0.2269)\n",
      "  - base_model.model.model.layers.9.self_attn.o_proj: r=5 (Unchanged, Score: 0.6365)\n",
      "  - base_model.model.model.layers.10.self_attn.q_proj: r=9 (Unchanged, Score: 0.9279)\n",
      "  - base_model.model.model.layers.10.self_attn.k_proj: r=7 (Unchanged, Score: 0.8203)\n",
      "  - base_model.model.model.layers.10.self_attn.v_proj: r=9 (Unchanged, Score: 0.9046)\n",
      "  - base_model.model.model.layers.10.self_attn.o_proj: r=2 (Unchanged, Score: 0.3112)\n",
      "  - base_model.model.model.layers.11.self_attn.q_proj: r=4 (Unchanged, Score: 0.6287)\n",
      "  - base_model.model.model.layers.11.self_attn.k_proj: r=5 (Unchanged, Score: 0.6592)\n",
      "  - base_model.model.model.layers.11.self_attn.v_proj: r=8 竊 9 (Score: 0.8837)\n",
      "  - base_model.model.model.layers.11.self_attn.o_proj: r=6 (Unchanged, Score: 0.7711)\n",
      "  - base_model.model.model.layers.12.self_attn.q_proj: r=11 (Unchanged, Score: 0.9747)\n",
      "  - base_model.model.model.layers.12.self_attn.k_proj: r=6 (Unchanged, Score: 0.7591)\n",
      "  - base_model.model.model.layers.12.self_attn.v_proj: r=8 (Unchanged, Score: 0.8594)\n",
      "  - base_model.model.model.layers.12.self_attn.o_proj: r=4 (Unchanged, Score: 0.5451)\n",
      "  - base_model.model.model.layers.13.self_attn.q_proj: r=5 (Unchanged, Score: 0.6863)\n",
      "  - base_model.model.model.layers.13.self_attn.k_proj: r=5 (Unchanged, Score: 0.6661)\n",
      "  - base_model.model.model.layers.13.self_attn.v_proj: r=5 (Unchanged, Score: 0.7002)\n",
      "  - base_model.model.model.layers.13.self_attn.o_proj: r=11 (Unchanged, Score: 0.9823)\n",
      "  - base_model.model.model.layers.14.self_attn.q_proj: r=6 (Unchanged, Score: 0.7366)\n",
      "  - base_model.model.model.layers.14.self_attn.k_proj: r=6 (Unchanged, Score: 0.7534)\n",
      "  - base_model.model.model.layers.14.self_attn.v_proj: r=2 (Unchanged, Score: 0.3826)\n",
      "  - base_model.model.model.layers.14.self_attn.o_proj: r=6 竊 5 (Score: 0.7098)\n",
      "  - base_model.model.model.layers.15.self_attn.q_proj: r=11 (Unchanged, Score: 0.9787)\n",
      "  - base_model.model.model.layers.15.self_attn.k_proj: r=7 (Unchanged, Score: 0.8111)\n",
      "  - base_model.model.model.layers.15.self_attn.v_proj: r=2 (Unchanged, Score: 0.3175)\n",
      "  - base_model.model.model.layers.15.self_attn.o_proj: r=3 (Unchanged, Score: 0.5075)\n",
      "  - base_model.model.model.layers.16.self_attn.q_proj: r=9 (Unchanged, Score: 0.8922)\n",
      "  - base_model.model.model.layers.16.self_attn.k_proj: r=5 (Unchanged, Score: 0.6551)\n",
      "  - base_model.model.model.layers.16.self_attn.v_proj: r=8 (Unchanged, Score: 0.8450)\n",
      "  - base_model.model.model.layers.16.self_attn.o_proj: r=7 (Unchanged, Score: 0.8277)\n",
      "  - base_model.model.model.layers.17.self_attn.q_proj: r=6 (Unchanged, Score: 0.7125)\n",
      "  - base_model.model.model.layers.17.self_attn.k_proj: r=6 (Unchanged, Score: 0.7613)\n",
      "  - base_model.model.model.layers.17.self_attn.v_proj: r=3 (Unchanged, Score: 0.4886)\n",
      "  - base_model.model.model.layers.17.self_attn.o_proj: r=4 (Unchanged, Score: 0.5456)\n",
      "  - base_model.model.model.layers.18.self_attn.q_proj: r=3 (Unchanged, Score: 0.4571)\n",
      "  - base_model.model.model.layers.18.self_attn.k_proj: r=2 (Unchanged, Score: 0.3026)\n",
      "  - base_model.model.model.layers.18.self_attn.v_proj: r=8 (Unchanged, Score: 0.8671)\n",
      "  - base_model.model.model.layers.18.self_attn.o_proj: r=2 (Unchanged, Score: 0.2312)\n",
      "  - base_model.model.model.layers.19.self_attn.q_proj: r=8 (Unchanged, Score: 0.8570)\n",
      "  - base_model.model.model.layers.19.self_attn.k_proj: r=4 (Unchanged, Score: 0.5334)\n",
      "  - base_model.model.model.layers.19.self_attn.v_proj: r=4 (Unchanged, Score: 0.5510)\n",
      "  - base_model.model.model.layers.19.self_attn.o_proj: r=5 (Unchanged, Score: 0.6330)\n",
      "  - base_model.model.model.layers.20.self_attn.q_proj: r=6 (Unchanged, Score: 0.7487)\n",
      "  - base_model.model.model.layers.20.self_attn.k_proj: r=4 (Unchanged, Score: 0.5432)\n",
      "  - base_model.model.model.layers.20.self_attn.v_proj: r=5 (Unchanged, Score: 0.6985)\n",
      "  - base_model.model.model.layers.20.self_attn.o_proj: r=4 (Unchanged, Score: 0.5472)\n",
      "  - base_model.model.model.layers.21.self_attn.q_proj: r=5 (Unchanged, Score: 0.6645)\n",
      "  - base_model.model.model.layers.21.self_attn.k_proj: r=10 (Unchanged, Score: 0.9529)\n",
      "  - base_model.model.model.layers.21.self_attn.v_proj: r=4 (Unchanged, Score: 0.6102)\n",
      "  - base_model.model.model.layers.21.self_attn.o_proj: r=6 (Unchanged, Score: 0.7163)\n",
      "  - base_model.model.model.layers.22.self_attn.q_proj: r=5 (Unchanged, Score: 0.6410)\n",
      "  - base_model.model.model.layers.22.self_attn.k_proj: r=3 (Unchanged, Score: 0.5245)\n",
      "  - base_model.model.model.layers.22.self_attn.v_proj: r=3 (Unchanged, Score: 0.5019)\n",
      "  - base_model.model.model.layers.22.self_attn.o_proj: r=4 (Unchanged, Score: 0.5890)\n",
      "  - base_model.model.model.layers.23.self_attn.q_proj: r=9 (Unchanged, Score: 0.9185)\n",
      "  - base_model.model.model.layers.23.self_attn.k_proj: r=3 (Unchanged, Score: 0.5194)\n",
      "  - base_model.model.model.layers.23.self_attn.v_proj: r=10 (Unchanged, Score: 0.9380)\n",
      "  - base_model.model.model.layers.23.self_attn.o_proj: r=1 (Unchanged, Score: 0.0000)\n",
      "笨 AdaptiveLoRA: Rank setup for Epoch 1 complete.\n",
      "\n",
      "沒 Epoch 2: Rank allocations logged to ./logs/adaptive_lora_epoch_logs.csv\n",
      "\n",
      "\n",
      "--- AdaptiveLoRA: Preparing ranks for Epoch 3 ---\n",
      "Computing BI importance scores (pre-training)...\n",
      "Allocating new ranks based on BI scores...\n",
      "Applying new ranks to LoRA modules for this epoch...\n",
      "  - base_model.model.model.layers.0.self_attn.q_proj: r=7 (Unchanged, Score: 0.8227)\n",
      "  - base_model.model.model.layers.0.self_attn.k_proj: r=4 (Unchanged, Score: 0.5497)\n",
      "  - base_model.model.model.layers.0.self_attn.v_proj: r=7 (Unchanged, Score: 0.8052)\n",
      "  - base_model.model.model.layers.0.self_attn.o_proj: r=4 (Unchanged, Score: 0.5330)\n",
      "  - base_model.model.model.layers.1.self_attn.q_proj: r=5 (Unchanged, Score: 0.6495)\n",
      "  - base_model.model.model.layers.1.self_attn.k_proj: r=9 (Unchanged, Score: 0.9009)\n",
      "  - base_model.model.model.layers.1.self_attn.v_proj: r=3 (Unchanged, Score: 0.4646)\n",
      "  - base_model.model.model.layers.1.self_attn.o_proj: r=7 (Unchanged, Score: 0.7840)\n",
      "  - base_model.model.model.layers.2.self_attn.q_proj: r=3 (Unchanged, Score: 0.4980)\n",
      "  - base_model.model.model.layers.2.self_attn.k_proj: r=7 (Unchanged, Score: 0.7778)\n",
      "  - base_model.model.model.layers.2.self_attn.v_proj: r=5 (Unchanged, Score: 0.6710)\n",
      "  - base_model.model.model.layers.2.self_attn.o_proj: r=3 (Unchanged, Score: 0.4708)\n",
      "  - base_model.model.model.layers.3.self_attn.q_proj: r=5 (Unchanged, Score: 0.6855)\n",
      "  - base_model.model.model.layers.3.self_attn.k_proj: r=5 (Unchanged, Score: 0.6800)\n",
      "  - base_model.model.model.layers.3.self_attn.v_proj: r=3 (Unchanged, Score: 0.4817)\n",
      "  - base_model.model.model.layers.3.self_attn.o_proj: r=4 (Unchanged, Score: 0.5409)\n",
      "  - base_model.model.model.layers.4.self_attn.q_proj: r=6 (Unchanged, Score: 0.7323)\n",
      "  - base_model.model.model.layers.4.self_attn.k_proj: r=6 (Unchanged, Score: 0.7197)\n",
      "  - base_model.model.model.layers.4.self_attn.v_proj: r=5 (Unchanged, Score: 0.6773)\n",
      "  - base_model.model.model.layers.4.self_attn.o_proj: r=3 (Unchanged, Score: 0.5285)\n",
      "  - base_model.model.model.layers.5.self_attn.q_proj: r=6 (Unchanged, Score: 0.7233)\n",
      "  - base_model.model.model.layers.5.self_attn.k_proj: r=4 (Unchanged, Score: 0.6044)\n",
      "  - base_model.model.model.layers.5.self_attn.v_proj: r=7 (Unchanged, Score: 0.8018)\n",
      "  - base_model.model.model.layers.5.self_attn.o_proj: r=6 (Unchanged, Score: 0.7456)\n",
      "  - base_model.model.model.layers.6.self_attn.q_proj: r=11 (Unchanged, Score: 1.0000)\n",
      "  - base_model.model.model.layers.6.self_attn.k_proj: r=8 (Unchanged, Score: 0.8376)\n",
      "  - base_model.model.model.layers.6.self_attn.v_proj: r=3 (Unchanged, Score: 0.4938)\n",
      "  - base_model.model.model.layers.6.self_attn.o_proj: r=4 (Unchanged, Score: 0.5381)\n",
      "  - base_model.model.model.layers.7.self_attn.q_proj: r=3 (Unchanged, Score: 0.4766)\n",
      "  - base_model.model.model.layers.7.self_attn.k_proj: r=3 (Unchanged, Score: 0.5001)\n",
      "  - base_model.model.model.layers.7.self_attn.v_proj: r=3 (Unchanged, Score: 0.5041)\n",
      "  - base_model.model.model.layers.7.self_attn.o_proj: r=5 (Unchanged, Score: 0.7094)\n",
      "  - base_model.model.model.layers.8.self_attn.q_proj: r=4 (Unchanged, Score: 0.5848)\n",
      "  - base_model.model.model.layers.8.self_attn.k_proj: r=6 (Unchanged, Score: 0.7275)\n",
      "  - base_model.model.model.layers.8.self_attn.v_proj: r=3 (Unchanged, Score: 0.5150)\n",
      "  - base_model.model.model.layers.8.self_attn.o_proj: r=6 (Unchanged, Score: 0.7338)\n",
      "  - base_model.model.model.layers.9.self_attn.q_proj: r=3 (Unchanged, Score: 0.4913)\n",
      "  - base_model.model.model.layers.9.self_attn.k_proj: r=5 (Unchanged, Score: 0.6515)\n",
      "  - base_model.model.model.layers.9.self_attn.v_proj: r=2 (Unchanged, Score: 0.2266)\n",
      "  - base_model.model.model.layers.9.self_attn.o_proj: r=5 (Unchanged, Score: 0.6366)\n",
      "  - base_model.model.model.layers.10.self_attn.q_proj: r=9 (Unchanged, Score: 0.9278)\n",
      "  - base_model.model.model.layers.10.self_attn.k_proj: r=7 (Unchanged, Score: 0.8202)\n",
      "  - base_model.model.model.layers.10.self_attn.v_proj: r=9 (Unchanged, Score: 0.9048)\n",
      "  - base_model.model.model.layers.10.self_attn.o_proj: r=2 (Unchanged, Score: 0.3111)\n",
      "  - base_model.model.model.layers.11.self_attn.q_proj: r=4 (Unchanged, Score: 0.6288)\n",
      "  - base_model.model.model.layers.11.self_attn.k_proj: r=5 (Unchanged, Score: 0.6594)\n",
      "  - base_model.model.model.layers.11.self_attn.v_proj: r=9 竊 8 (Score: 0.8833)\n",
      "  - base_model.model.model.layers.11.self_attn.o_proj: r=6 (Unchanged, Score: 0.7713)\n",
      "  - base_model.model.model.layers.12.self_attn.q_proj: r=11 (Unchanged, Score: 0.9747)\n",
      "  - base_model.model.model.layers.12.self_attn.k_proj: r=6 (Unchanged, Score: 0.7592)\n",
      "  - base_model.model.model.layers.12.self_attn.v_proj: r=8 (Unchanged, Score: 0.8597)\n",
      "  - base_model.model.model.layers.12.self_attn.o_proj: r=4 (Unchanged, Score: 0.5447)\n",
      "  - base_model.model.model.layers.13.self_attn.q_proj: r=5 (Unchanged, Score: 0.6864)\n",
      "  - base_model.model.model.layers.13.self_attn.k_proj: r=5 (Unchanged, Score: 0.6663)\n",
      "  - base_model.model.model.layers.13.self_attn.v_proj: r=5 (Unchanged, Score: 0.7004)\n",
      "  - base_model.model.model.layers.13.self_attn.o_proj: r=11 (Unchanged, Score: 0.9829)\n",
      "  - base_model.model.model.layers.14.self_attn.q_proj: r=6 (Unchanged, Score: 0.7365)\n",
      "  - base_model.model.model.layers.14.self_attn.k_proj: r=6 (Unchanged, Score: 0.7534)\n",
      "  - base_model.model.model.layers.14.self_attn.v_proj: r=2 (Unchanged, Score: 0.3818)\n",
      "  - base_model.model.model.layers.14.self_attn.o_proj: r=5 竊 6 (Score: 0.7097)\n",
      "  - base_model.model.model.layers.15.self_attn.q_proj: r=11 (Unchanged, Score: 0.9782)\n",
      "  - base_model.model.model.layers.15.self_attn.k_proj: r=7 (Unchanged, Score: 0.8110)\n",
      "  - base_model.model.model.layers.15.self_attn.v_proj: r=2 (Unchanged, Score: 0.3172)\n",
      "  - base_model.model.model.layers.15.self_attn.o_proj: r=3 (Unchanged, Score: 0.5080)\n",
      "  - base_model.model.model.layers.16.self_attn.q_proj: r=9 (Unchanged, Score: 0.8921)\n",
      "  - base_model.model.model.layers.16.self_attn.k_proj: r=5 (Unchanged, Score: 0.6549)\n",
      "  - base_model.model.model.layers.16.self_attn.v_proj: r=8 (Unchanged, Score: 0.8454)\n",
      "  - base_model.model.model.layers.16.self_attn.o_proj: r=7 (Unchanged, Score: 0.8262)\n",
      "  - base_model.model.model.layers.17.self_attn.q_proj: r=6 (Unchanged, Score: 0.7124)\n",
      "  - base_model.model.model.layers.17.self_attn.k_proj: r=6 (Unchanged, Score: 0.7612)\n",
      "  - base_model.model.model.layers.17.self_attn.v_proj: r=3 (Unchanged, Score: 0.4891)\n",
      "  - base_model.model.model.layers.17.self_attn.o_proj: r=4 (Unchanged, Score: 0.5449)\n",
      "  - base_model.model.model.layers.18.self_attn.q_proj: r=3 (Unchanged, Score: 0.4575)\n",
      "  - base_model.model.model.layers.18.self_attn.k_proj: r=2 (Unchanged, Score: 0.3028)\n",
      "  - base_model.model.model.layers.18.self_attn.v_proj: r=8 (Unchanged, Score: 0.8680)\n",
      "  - base_model.model.model.layers.18.self_attn.o_proj: r=2 (Unchanged, Score: 0.2316)\n",
      "  - base_model.model.model.layers.19.self_attn.q_proj: r=8 (Unchanged, Score: 0.8572)\n",
      "  - base_model.model.model.layers.19.self_attn.k_proj: r=4 (Unchanged, Score: 0.5329)\n",
      "  - base_model.model.model.layers.19.self_attn.v_proj: r=4 (Unchanged, Score: 0.5513)\n",
      "  - base_model.model.model.layers.19.self_attn.o_proj: r=5 (Unchanged, Score: 0.6328)\n",
      "  - base_model.model.model.layers.20.self_attn.q_proj: r=6 (Unchanged, Score: 0.7491)\n",
      "  - base_model.model.model.layers.20.self_attn.k_proj: r=4 (Unchanged, Score: 0.5432)\n",
      "  - base_model.model.model.layers.20.self_attn.v_proj: r=5 (Unchanged, Score: 0.6991)\n",
      "  - base_model.model.model.layers.20.self_attn.o_proj: r=4 (Unchanged, Score: 0.5470)\n",
      "  - base_model.model.model.layers.21.self_attn.q_proj: r=5 (Unchanged, Score: 0.6643)\n",
      "  - base_model.model.model.layers.21.self_attn.k_proj: r=10 (Unchanged, Score: 0.9531)\n",
      "  - base_model.model.model.layers.21.self_attn.v_proj: r=4 (Unchanged, Score: 0.6106)\n",
      "  - base_model.model.model.layers.21.self_attn.o_proj: r=6 (Unchanged, Score: 0.7177)\n",
      "  - base_model.model.model.layers.22.self_attn.q_proj: r=5 (Unchanged, Score: 0.6413)\n",
      "  - base_model.model.model.layers.22.self_attn.k_proj: r=3 (Unchanged, Score: 0.5247)\n",
      "  - base_model.model.model.layers.22.self_attn.v_proj: r=3 (Unchanged, Score: 0.5021)\n",
      "  - base_model.model.model.layers.22.self_attn.o_proj: r=4 (Unchanged, Score: 0.5900)\n",
      "  - base_model.model.model.layers.23.self_attn.q_proj: r=9 (Unchanged, Score: 0.9185)\n",
      "  - base_model.model.model.layers.23.self_attn.k_proj: r=3 (Unchanged, Score: 0.5191)\n",
      "  - base_model.model.model.layers.23.self_attn.v_proj: r=10 (Unchanged, Score: 0.9377)\n",
      "  - base_model.model.model.layers.23.self_attn.o_proj: r=1 (Unchanged, Score: 0.0000)\n",
      "笨 AdaptiveLoRA: Rank setup for Epoch 3 complete.\n",
      "\n",
      "沒 Epoch 2: Rank allocations logged to ./logs/adaptive_lora_epoch_logs.csv\n",
      "\n",
      "\n",
      "--- AdaptiveLoRA: Preparing ranks for Epoch 3 ---\n",
      "Computing BI importance scores (pre-training)...\n",
      "Allocating new ranks based on BI scores...\n",
      "Applying new ranks to LoRA modules for this epoch...\n",
      "  - base_model.model.model.layers.0.self_attn.q_proj: r=7 (Unchanged, Score: 0.8227)\n",
      "  - base_model.model.model.layers.0.self_attn.k_proj: r=4 (Unchanged, Score: 0.5498)\n",
      "  - base_model.model.model.layers.0.self_attn.v_proj: r=7 (Unchanged, Score: 0.8053)\n",
      "  - base_model.model.model.layers.0.self_attn.o_proj: r=4 (Unchanged, Score: 0.5331)\n",
      "  - base_model.model.model.layers.1.self_attn.q_proj: r=5 (Unchanged, Score: 0.6497)\n",
      "  - base_model.model.model.layers.1.self_attn.k_proj: r=9 (Unchanged, Score: 0.9009)\n",
      "  - base_model.model.model.layers.1.self_attn.v_proj: r=3 (Unchanged, Score: 0.4648)\n",
      "  - base_model.model.model.layers.1.self_attn.o_proj: r=7 (Unchanged, Score: 0.7841)\n",
      "  - base_model.model.model.layers.2.self_attn.q_proj: r=3 (Unchanged, Score: 0.4981)\n",
      "  - base_model.model.model.layers.2.self_attn.k_proj: r=7 (Unchanged, Score: 0.7779)\n",
      "  - base_model.model.model.layers.2.self_attn.v_proj: r=5 (Unchanged, Score: 0.6711)\n",
      "  - base_model.model.model.layers.2.self_attn.o_proj: r=3 (Unchanged, Score: 0.4710)\n",
      "  - base_model.model.model.layers.3.self_attn.q_proj: r=5 (Unchanged, Score: 0.6856)\n",
      "  - base_model.model.model.layers.3.self_attn.k_proj: r=5 (Unchanged, Score: 0.6801)\n",
      "  - base_model.model.model.layers.3.self_attn.v_proj: r=3 (Unchanged, Score: 0.4818)\n",
      "  - base_model.model.model.layers.3.self_attn.o_proj: r=4 (Unchanged, Score: 0.5410)\n",
      "  - base_model.model.model.layers.4.self_attn.q_proj: r=6 (Unchanged, Score: 0.7324)\n",
      "  - base_model.model.model.layers.4.self_attn.k_proj: r=6 (Unchanged, Score: 0.7198)\n",
      "  - base_model.model.model.layers.4.self_attn.v_proj: r=5 (Unchanged, Score: 0.6774)\n",
      "  - base_model.model.model.layers.4.self_attn.o_proj: r=3 (Unchanged, Score: 0.5287)\n",
      "  - base_model.model.model.layers.5.self_attn.q_proj: r=6 (Unchanged, Score: 0.7234)\n",
      "  - base_model.model.model.layers.5.self_attn.k_proj: r=4 (Unchanged, Score: 0.6046)\n",
      "  - base_model.model.model.layers.5.self_attn.v_proj: r=7 (Unchanged, Score: 0.8019)\n",
      "  - base_model.model.model.layers.5.self_attn.o_proj: r=6 (Unchanged, Score: 0.7457)\n",
      "  - base_model.model.model.layers.6.self_attn.q_proj: r=11 (Unchanged, Score: 1.0000)\n",
      "  - base_model.model.model.layers.6.self_attn.k_proj: r=8 (Unchanged, Score: 0.8377)\n",
      "  - base_model.model.model.layers.6.self_attn.v_proj: r=3 (Unchanged, Score: 0.4939)\n",
      "  - base_model.model.model.layers.6.self_attn.o_proj: r=4 (Unchanged, Score: 0.5383)\n",
      "  - base_model.model.model.layers.7.self_attn.q_proj: r=3 (Unchanged, Score: 0.4768)\n",
      "  - base_model.model.model.layers.7.self_attn.k_proj: r=3 (Unchanged, Score: 0.5002)\n",
      "  - base_model.model.model.layers.7.self_attn.v_proj: r=3 (Unchanged, Score: 0.5042)\n",
      "  - base_model.model.model.layers.7.self_attn.o_proj: r=5 (Unchanged, Score: 0.7095)\n",
      "  - base_model.model.model.layers.8.self_attn.q_proj: r=4 (Unchanged, Score: 0.5848)\n",
      "  - base_model.model.model.layers.8.self_attn.k_proj: r=6 (Unchanged, Score: 0.7276)\n",
      "  - base_model.model.model.layers.8.self_attn.v_proj: r=3 (Unchanged, Score: 0.5151)\n",
      "  - base_model.model.model.layers.8.self_attn.o_proj: r=6 (Unchanged, Score: 0.7338)\n",
      "  - base_model.model.model.layers.9.self_attn.q_proj: r=3 (Unchanged, Score: 0.4915)\n",
      "  - base_model.model.model.layers.9.self_attn.k_proj: r=5 (Unchanged, Score: 0.6518)\n",
      "  - base_model.model.model.layers.9.self_attn.v_proj: r=2 (Unchanged, Score: 0.2271)\n",
      "  - base_model.model.model.layers.9.self_attn.o_proj: r=5 (Unchanged, Score: 0.6367)\n",
      "  - base_model.model.model.layers.10.self_attn.q_proj: r=9 (Unchanged, Score: 0.9279)\n",
      "  - base_model.model.model.layers.10.self_attn.k_proj: r=7 (Unchanged, Score: 0.8204)\n",
      "  - base_model.model.model.layers.10.self_attn.v_proj: r=9 (Unchanged, Score: 0.9048)\n",
      "  - base_model.model.model.layers.10.self_attn.o_proj: r=2 (Unchanged, Score: 0.3114)\n",
      "  - base_model.model.model.layers.11.self_attn.q_proj: r=4 (Unchanged, Score: 0.6290)\n",
      "  - base_model.model.model.layers.11.self_attn.k_proj: r=5 (Unchanged, Score: 0.6594)\n",
      "  - base_model.model.model.layers.11.self_attn.v_proj: r=8 (Unchanged, Score: 0.8835)\n",
      "  - base_model.model.model.layers.11.self_attn.o_proj: r=6 (Unchanged, Score: 0.7709)\n",
      "  - base_model.model.model.layers.12.self_attn.q_proj: r=11 (Unchanged, Score: 0.9748)\n",
      "  - base_model.model.model.layers.12.self_attn.k_proj: r=6 (Unchanged, Score: 0.7592)\n",
      "  - base_model.model.model.layers.12.self_attn.v_proj: r=8 (Unchanged, Score: 0.8591)\n",
      "  - base_model.model.model.layers.12.self_attn.o_proj: r=4 (Unchanged, Score: 0.5445)\n",
      "  - base_model.model.model.layers.13.self_attn.q_proj: r=5 (Unchanged, Score: 0.6863)\n",
      "  - base_model.model.model.layers.13.self_attn.k_proj: r=5 (Unchanged, Score: 0.6663)\n",
      "  - base_model.model.model.layers.13.self_attn.v_proj: r=5 (Unchanged, Score: 0.6996)\n",
      "  - base_model.model.model.layers.13.self_attn.o_proj: r=11 (Unchanged, Score: 0.9825)\n",
      "  - base_model.model.model.layers.14.self_attn.q_proj: r=6 (Unchanged, Score: 0.7366)\n",
      "  - base_model.model.model.layers.14.self_attn.k_proj: r=6 (Unchanged, Score: 0.7532)\n",
      "  - base_model.model.model.layers.14.self_attn.v_proj: r=2 (Unchanged, Score: 0.3816)\n",
      "  - base_model.model.model.layers.14.self_attn.o_proj: r=6 (Unchanged, Score: 0.7103)\n",
      "  - base_model.model.model.layers.15.self_attn.q_proj: r=11 (Unchanged, Score: 0.9786)\n",
      "  - base_model.model.model.layers.15.self_attn.k_proj: r=7 (Unchanged, Score: 0.8110)\n",
      "  - base_model.model.model.layers.15.self_attn.v_proj: r=2 (Unchanged, Score: 0.3176)\n",
      "  - base_model.model.model.layers.15.self_attn.o_proj: r=3 (Unchanged, Score: 0.5080)\n",
      "  - base_model.model.model.layers.16.self_attn.q_proj: r=9 (Unchanged, Score: 0.8920)\n",
      "  - base_model.model.model.layers.16.self_attn.k_proj: r=5 (Unchanged, Score: 0.6550)\n",
      "  - base_model.model.model.layers.16.self_attn.v_proj: r=8 (Unchanged, Score: 0.8449)\n",
      "  - base_model.model.model.layers.16.self_attn.o_proj: r=7 (Unchanged, Score: 0.8267)\n",
      "  - base_model.model.model.layers.17.self_attn.q_proj: r=6 (Unchanged, Score: 0.7127)\n",
      "  - base_model.model.model.layers.17.self_attn.k_proj: r=6 (Unchanged, Score: 0.7616)\n",
      "  - base_model.model.model.layers.17.self_attn.v_proj: r=3 (Unchanged, Score: 0.4890)\n",
      "  - base_model.model.model.layers.17.self_attn.o_proj: r=4 (Unchanged, Score: 0.5456)\n",
      "  - base_model.model.model.layers.18.self_attn.q_proj: r=3 (Unchanged, Score: 0.4576)\n",
      "  - base_model.model.model.layers.18.self_attn.k_proj: r=2 (Unchanged, Score: 0.3029)\n",
      "  - base_model.model.model.layers.18.self_attn.v_proj: r=8 (Unchanged, Score: 0.8671)\n",
      "  - base_model.model.model.layers.18.self_attn.o_proj: r=2 (Unchanged, Score: 0.2320)\n",
      "  - base_model.model.model.layers.19.self_attn.q_proj: r=8 (Unchanged, Score: 0.8571)\n",
      "  - base_model.model.model.layers.19.self_attn.k_proj: r=4 (Unchanged, Score: 0.5337)\n",
      "  - base_model.model.model.layers.19.self_attn.v_proj: r=4 (Unchanged, Score: 0.5516)\n",
      "  - base_model.model.model.layers.19.self_attn.o_proj: r=5 (Unchanged, Score: 0.6328)\n",
      "  - base_model.model.model.layers.20.self_attn.q_proj: r=6 (Unchanged, Score: 0.7490)\n",
      "  - base_model.model.model.layers.20.self_attn.k_proj: r=4 (Unchanged, Score: 0.5433)\n",
      "  - base_model.model.model.layers.20.self_attn.v_proj: r=5 (Unchanged, Score: 0.6995)\n",
      "  - base_model.model.model.layers.20.self_attn.o_proj: r=4 (Unchanged, Score: 0.5476)\n",
      "  - base_model.model.model.layers.21.self_attn.q_proj: r=5 (Unchanged, Score: 0.6644)\n",
      "  - base_model.model.model.layers.21.self_attn.k_proj: r=10 (Unchanged, Score: 0.9530)\n",
      "  - base_model.model.model.layers.21.self_attn.v_proj: r=4 (Unchanged, Score: 0.6113)\n",
      "  - base_model.model.model.layers.21.self_attn.o_proj: r=6 (Unchanged, Score: 0.7175)\n",
      "  - base_model.model.model.layers.22.self_attn.q_proj: r=5 (Unchanged, Score: 0.6411)\n",
      "  - base_model.model.model.layers.22.self_attn.k_proj: r=3 (Unchanged, Score: 0.5249)\n",
      "  - base_model.model.model.layers.22.self_attn.v_proj: r=3 (Unchanged, Score: 0.5021)\n",
      "  - base_model.model.model.layers.22.self_attn.o_proj: r=4 (Unchanged, Score: 0.5901)\n",
      "  - base_model.model.model.layers.23.self_attn.q_proj: r=9 (Unchanged, Score: 0.9185)\n",
      "  - base_model.model.model.layers.23.self_attn.k_proj: r=3 (Unchanged, Score: 0.5190)\n",
      "  - base_model.model.model.layers.23.self_attn.v_proj: r=10 (Unchanged, Score: 0.9377)\n",
      "  - base_model.model.model.layers.23.self_attn.o_proj: r=1 (Unchanged, Score: 0.0000)\n",
      "笨 AdaptiveLoRA: Rank setup for Epoch 3 complete.\n",
      "\n",
      "沒 Epoch 4: Rank allocations logged to ./logs/adaptive_lora_epoch_logs.csv\n",
      "\n",
      "\n",
      "--- AdaptiveLoRA: Preparing ranks for Epoch 5 ---\n",
      "Computing BI importance scores (pre-training)...\n",
      "Allocating new ranks based on BI scores...\n",
      "Applying new ranks to LoRA modules for this epoch...\n",
      "  - base_model.model.model.layers.0.self_attn.q_proj: r=7 (Unchanged, Score: 0.8227)\n",
      "  - base_model.model.model.layers.0.self_attn.k_proj: r=4 (Unchanged, Score: 0.5498)\n",
      "  - base_model.model.model.layers.0.self_attn.v_proj: r=7 (Unchanged, Score: 0.8053)\n",
      "  - base_model.model.model.layers.0.self_attn.o_proj: r=4 (Unchanged, Score: 0.5331)\n",
      "  - base_model.model.model.layers.1.self_attn.q_proj: r=5 (Unchanged, Score: 0.6496)\n",
      "  - base_model.model.model.layers.1.self_attn.k_proj: r=9 (Unchanged, Score: 0.9009)\n",
      "  - base_model.model.model.layers.1.self_attn.v_proj: r=3 (Unchanged, Score: 0.4648)\n",
      "  - base_model.model.model.layers.1.self_attn.o_proj: r=7 (Unchanged, Score: 0.7841)\n",
      "  - base_model.model.model.layers.2.self_attn.q_proj: r=3 (Unchanged, Score: 0.4981)\n",
      "  - base_model.model.model.layers.2.self_attn.k_proj: r=7 (Unchanged, Score: 0.7778)\n",
      "  - base_model.model.model.layers.2.self_attn.v_proj: r=5 (Unchanged, Score: 0.6711)\n",
      "  - base_model.model.model.layers.2.self_attn.o_proj: r=3 (Unchanged, Score: 0.4709)\n",
      "  - base_model.model.model.layers.3.self_attn.q_proj: r=5 (Unchanged, Score: 0.6855)\n",
      "  - base_model.model.model.layers.3.self_attn.k_proj: r=5 (Unchanged, Score: 0.6801)\n",
      "  - base_model.model.model.layers.3.self_attn.v_proj: r=3 (Unchanged, Score: 0.4818)\n",
      "  - base_model.model.model.layers.3.self_attn.o_proj: r=4 (Unchanged, Score: 0.5410)\n",
      "  - base_model.model.model.layers.4.self_attn.q_proj: r=6 (Unchanged, Score: 0.7324)\n",
      "  - base_model.model.model.layers.4.self_attn.k_proj: r=6 (Unchanged, Score: 0.7198)\n",
      "  - base_model.model.model.layers.4.self_attn.v_proj: r=5 (Unchanged, Score: 0.6774)\n",
      "  - base_model.model.model.layers.4.self_attn.o_proj: r=3 (Unchanged, Score: 0.5286)\n",
      "  - base_model.model.model.layers.5.self_attn.q_proj: r=6 (Unchanged, Score: 0.7234)\n",
      "  - base_model.model.model.layers.5.self_attn.k_proj: r=4 (Unchanged, Score: 0.6045)\n",
      "  - base_model.model.model.layers.5.self_attn.v_proj: r=7 (Unchanged, Score: 0.8019)\n",
      "  - base_model.model.model.layers.5.self_attn.o_proj: r=6 (Unchanged, Score: 0.7457)\n",
      "  - base_model.model.model.layers.6.self_attn.q_proj: r=11 (Unchanged, Score: 1.0000)\n",
      "  - base_model.model.model.layers.6.self_attn.k_proj: r=8 (Unchanged, Score: 0.8376)\n",
      "  - base_model.model.model.layers.6.self_attn.v_proj: r=3 (Unchanged, Score: 0.4939)\n",
      "  - base_model.model.model.layers.6.self_attn.o_proj: r=4 (Unchanged, Score: 0.5382)\n",
      "  - base_model.model.model.layers.7.self_attn.q_proj: r=3 (Unchanged, Score: 0.4767)\n",
      "  - base_model.model.model.layers.7.self_attn.k_proj: r=3 (Unchanged, Score: 0.5002)\n",
      "  - base_model.model.model.layers.7.self_attn.v_proj: r=3 (Unchanged, Score: 0.5042)\n",
      "  - base_model.model.model.layers.7.self_attn.o_proj: r=5 (Unchanged, Score: 0.7095)\n",
      "  - base_model.model.model.layers.8.self_attn.q_proj: r=4 (Unchanged, Score: 0.5849)\n",
      "  - base_model.model.model.layers.8.self_attn.k_proj: r=6 (Unchanged, Score: 0.7276)\n",
      "  - base_model.model.model.layers.8.self_attn.v_proj: r=3 (Unchanged, Score: 0.5149)\n",
      "  - base_model.model.model.layers.8.self_attn.o_proj: r=6 (Unchanged, Score: 0.7337)\n",
      "  - base_model.model.model.layers.9.self_attn.q_proj: r=3 (Unchanged, Score: 0.4914)\n",
      "  - base_model.model.model.layers.9.self_attn.k_proj: r=5 (Unchanged, Score: 0.6516)\n",
      "  - base_model.model.model.layers.9.self_attn.v_proj: r=2 (Unchanged, Score: 0.2271)\n",
      "  - base_model.model.model.layers.9.self_attn.o_proj: r=5 (Unchanged, Score: 0.6367)\n",
      "  - base_model.model.model.layers.10.self_attn.q_proj: r=9 (Unchanged, Score: 0.9279)\n",
      "  - base_model.model.model.layers.10.self_attn.k_proj: r=7 (Unchanged, Score: 0.8203)\n",
      "  - base_model.model.model.layers.10.self_attn.v_proj: r=9 (Unchanged, Score: 0.9048)\n",
      "  - base_model.model.model.layers.10.self_attn.o_proj: r=2 (Unchanged, Score: 0.3114)\n",
      "  - base_model.model.model.layers.11.self_attn.q_proj: r=4 (Unchanged, Score: 0.6289)\n",
      "  - base_model.model.model.layers.11.self_attn.k_proj: r=5 (Unchanged, Score: 0.6594)\n",
      "  - base_model.model.model.layers.11.self_attn.v_proj: r=8 (Unchanged, Score: 0.8837)\n",
      "  - base_model.model.model.layers.11.self_attn.o_proj: r=6 (Unchanged, Score: 0.7711)\n",
      "  - base_model.model.model.layers.12.self_attn.q_proj: r=11 (Unchanged, Score: 0.9746)\n",
      "  - base_model.model.model.layers.12.self_attn.k_proj: r=6 (Unchanged, Score: 0.7591)\n",
      "  - base_model.model.model.layers.12.self_attn.v_proj: r=8 (Unchanged, Score: 0.8592)\n",
      "  - base_model.model.model.layers.12.self_attn.o_proj: r=4 (Unchanged, Score: 0.5445)\n",
      "  - base_model.model.model.layers.13.self_attn.q_proj: r=5 (Unchanged, Score: 0.6865)\n",
      "  - base_model.model.model.layers.13.self_attn.k_proj: r=5 (Unchanged, Score: 0.6665)\n",
      "  - base_model.model.model.layers.13.self_attn.v_proj: r=5 (Unchanged, Score: 0.6997)\n",
      "  - base_model.model.model.layers.13.self_attn.o_proj: r=11 (Unchanged, Score: 0.9823)\n",
      "  - base_model.model.model.layers.14.self_attn.q_proj: r=6 (Unchanged, Score: 0.7369)\n",
      "  - base_model.model.model.layers.14.self_attn.k_proj: r=6 (Unchanged, Score: 0.7536)\n",
      "  - base_model.model.model.layers.14.self_attn.v_proj: r=2 (Unchanged, Score: 0.3815)\n",
      "  - base_model.model.model.layers.14.self_attn.o_proj: r=6 (Unchanged, Score: 0.7106)\n",
      "  - base_model.model.model.layers.15.self_attn.q_proj: r=11 (Unchanged, Score: 0.9783)\n",
      "  - base_model.model.model.layers.15.self_attn.k_proj: r=7 (Unchanged, Score: 0.8111)\n",
      "  - base_model.model.model.layers.15.self_attn.v_proj: r=2 (Unchanged, Score: 0.3174)\n",
      "  - base_model.model.model.layers.15.self_attn.o_proj: r=3 (Unchanged, Score: 0.5083)\n",
      "  - base_model.model.model.layers.16.self_attn.q_proj: r=9 (Unchanged, Score: 0.8922)\n",
      "  - base_model.model.model.layers.16.self_attn.k_proj: r=5 (Unchanged, Score: 0.6552)\n",
      "  - base_model.model.model.layers.16.self_attn.v_proj: r=8 (Unchanged, Score: 0.8454)\n",
      "  - base_model.model.model.layers.16.self_attn.o_proj: r=7 (Unchanged, Score: 0.8275)\n",
      "  - base_model.model.model.layers.17.self_attn.q_proj: r=6 (Unchanged, Score: 0.7127)\n",
      "  - base_model.model.model.layers.17.self_attn.k_proj: r=6 (Unchanged, Score: 0.7614)\n",
      "  - base_model.model.model.layers.17.self_attn.v_proj: r=3 (Unchanged, Score: 0.4893)\n",
      "  - base_model.model.model.layers.17.self_attn.o_proj: r=4 (Unchanged, Score: 0.5459)\n",
      "  - base_model.model.model.layers.18.self_attn.q_proj: r=3 (Unchanged, Score: 0.4576)\n",
      "  - base_model.model.model.layers.18.self_attn.k_proj: r=2 (Unchanged, Score: 0.3029)\n",
      "  - base_model.model.model.layers.18.self_attn.v_proj: r=8 (Unchanged, Score: 0.8668)\n",
      "  - base_model.model.model.layers.18.self_attn.o_proj: r=2 (Unchanged, Score: 0.2334)\n",
      "  - base_model.model.model.layers.19.self_attn.q_proj: r=8 (Unchanged, Score: 0.8569)\n",
      "  - base_model.model.model.layers.19.self_attn.k_proj: r=4 (Unchanged, Score: 0.5327)\n",
      "  - base_model.model.model.layers.19.self_attn.v_proj: r=4 (Unchanged, Score: 0.5513)\n",
      "  - base_model.model.model.layers.19.self_attn.o_proj: r=5 (Unchanged, Score: 0.6332)\n",
      "  - base_model.model.model.layers.20.self_attn.q_proj: r=6 (Unchanged, Score: 0.7489)\n",
      "  - base_model.model.model.layers.20.self_attn.k_proj: r=4 (Unchanged, Score: 0.5435)\n",
      "  - base_model.model.model.layers.20.self_attn.v_proj: r=5 (Unchanged, Score: 0.6995)\n",
      "  - base_model.model.model.layers.20.self_attn.o_proj: r=4 (Unchanged, Score: 0.5474)\n",
      "  - base_model.model.model.layers.21.self_attn.q_proj: r=5 (Unchanged, Score: 0.6645)\n",
      "  - base_model.model.model.layers.21.self_attn.k_proj: r=10 (Unchanged, Score: 0.9532)\n",
      "  - base_model.model.model.layers.21.self_attn.v_proj: r=4 (Unchanged, Score: 0.6106)\n",
      "  - base_model.model.model.layers.21.self_attn.o_proj: r=6 (Unchanged, Score: 0.7172)\n",
      "  - base_model.model.model.layers.22.self_attn.q_proj: r=5 (Unchanged, Score: 0.6413)\n",
      "  - base_model.model.model.layers.22.self_attn.k_proj: r=3 (Unchanged, Score: 0.5247)\n",
      "  - base_model.model.model.layers.22.self_attn.v_proj: r=3 (Unchanged, Score: 0.5018)\n",
      "  - base_model.model.model.layers.22.self_attn.o_proj: r=4 (Unchanged, Score: 0.5905)\n",
      "  - base_model.model.model.layers.23.self_attn.q_proj: r=9 (Unchanged, Score: 0.9184)\n",
      "  - base_model.model.model.layers.23.self_attn.k_proj: r=3 (Unchanged, Score: 0.5193)\n",
      "  - base_model.model.model.layers.23.self_attn.v_proj: r=10 (Unchanged, Score: 0.9375)\n",
      "  - base_model.model.model.layers.23.self_attn.o_proj: r=1 (Unchanged, Score: 0.0000)\n",
      "笨 AdaptiveLoRA: Rank setup for Epoch 5 complete.\n",
      "\n",
      "沒 Epoch 4: Rank allocations logged to ./logs/adaptive_lora_epoch_logs.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12, training_loss=5.820412953694661, metrics={'train_runtime': 38.2101, 'train_samples_per_second': 1.57, 'train_steps_per_second': 0.314, 'total_flos': 47285258944512.0, 'train_loss': 5.820412953694661, 'epoch': 4.8})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7ｸ鞘Ε Training Arguments\n",
    "# ============================================================\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./deepseek_wiki_results\",\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    bf16=True,   # 笨 mixed precision for efficiency\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,  # 笨 added here\n",
    "    callbacks=[adaptive_callback],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 沐･ 9ｸ鞘Ε Train the Model\n",
    "# ============================================================\n",
    "print(\"\\n泅 Starting Adaptive LoRA fine-tuning on WikiText...\")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:15:02.434486Z",
     "iopub.status.busy": "2025-11-09T09:15:02.433859Z",
     "iopub.status.idle": "2025-11-09T09:15:02.747361Z",
     "shell.execute_reply": "2025-11-09T09:15:02.746455Z",
     "shell.execute_reply.started": "2025-11-09T09:15:02.434433Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "沐 Final Evaluation on Test Split...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.633203983306885, 'eval_perplexity': 2065.65771484375, 'eval_bleu': 0.0, 'eval_runtime': 0.3035, 'eval_samples_per_second': 6.589, 'eval_steps_per_second': 3.295, 'epoch': 4.8}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 沐 沐 Evaluate on Test Set\n",
    "# ============================================================\n",
    "print(\"\\n沐 Final Evaluation on Test Split...\")\n",
    "metrics = trainer.evaluate(test_dataset)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
